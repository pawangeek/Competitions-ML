{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/amazonml/train.csv')\n",
    "test = pd.read_csv('../input/amazonml/test.csv')\n",
    "tests = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5959 2553\n",
      "4196 1772\n"
     ]
    }
   ],
   "source": [
    "print(len(train['Review Text']),len(test['Review Text']))\n",
    "print(len(train['Review Text'].value_counts()),len(test['Review Text'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_review = LabelEncoder()\n",
    "\n",
    "le_review.fit(train['topic'])\n",
    "train['topic'] = le_review.transform(train['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['topic'] = train['topic'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review'] = train['Review Text']+' '+train['Review Title']\n",
    "train.drop(['Review Text','Review Title'],axis=1,inplace=True)\n",
    "\n",
    "test['review'] = test['Review Text']+' '+test['Review Title']\n",
    "test.drop(['Review Text','Review Title'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5959\n",
      "5948\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "train = train.drop_duplicates()\n",
    "\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.groupby(['review'],sort=False)['topic'].apply(', '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, train['topic'].str.get_dummies(sep=', ')],axis=1)\n",
    "train.drop(['topic'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review'] = train['review'].str.lower()\n",
    "test['review'] = test['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553\n"
     ]
    }
   ],
   "source": [
    "print(len(test))\n",
    "test = test.groupby(['review'],sort=False).agg({'review':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1776\n"
     ]
    }
   ],
   "source": [
    "test.index.name = None\n",
    "test = test.reset_index()\n",
    "\n",
    "test = test.rename(columns={\"review\": \"count\", \"index\": \"review\"})\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\n",
    "    \"'cause\": 'because','Ã¢â‚¬â„¢': \"'\",',cause': 'because',';cause': 'because',\"ain't\": 'am not','ain,t': 'am not','<br />':' ','&quot;':'\"',\n",
    "    'ain;t': 'am not','ainÂ´t': 'am not','ainâ€™t': 'am not',\"aren't\": 'are not','Ã¢â‚¬â€œ': '-','Ã¢â‚¬Å“':'\"',\n",
    "    'aren,t': 'are not','aren;t': 'are not','arenÂ´t': 'are not','arenâ€™t': 'are not',\"can't\": 'cannot',\"can't've\": 'cannot have','can,t': 'cannot','can,t,ve': 'cannot have',\n",
    "    'can;t': 'cannot','can;t;ve': 'cannot have',\n",
    "    'canÂ´t': 'cannot','canÂ´tÂ´ve': 'cannot have','canâ€™t': 'cannot','canâ€™tâ€™ve': 'cannot have',\n",
    "    \"could've\": 'could have','could,ve': 'could have','could;ve': 'could have',\"couldn't\": 'could not',\"couldn't've\": 'could not have','couldn,t': 'could not','couldn,t,ve': 'could not have','couldn;t': 'could not',\n",
    "    'couldn;t;ve': 'could not have','couldnÂ´t': 'could not',\n",
    "    'couldnÂ´tÂ´ve': 'could not have','couldnâ€™t': 'could not','couldnâ€™tâ€™ve': 'could not have','couldÂ´ve': 'could have',\n",
    "    'couldâ€™ve': 'could have',\"didn't\": 'did not','didn,t': 'did not','didn;t': 'did not','didnÂ´t': 'did not',\n",
    "    'didnâ€™t': 'did not',\"doesn't\": 'does not','doesn,t': 'does not','doesn;t': 'does not','doesnÂ´t': 'does not',\n",
    "    'doesnâ€™t': 'does not',\"don't\": 'do not','don,t': 'do not','don;t': 'do not','donÂ´t': 'do not','donâ€™t': 'do not',\n",
    "    \"hadn't\": 'had not',\"hadn't've\": 'had not have','hadn,t': 'had not','hadn,t,ve': 'had not have','hadn;t': 'had not',\n",
    "    'hadn;t;ve': 'had not have','hadnÂ´t': 'had not','hadnÂ´tÂ´ve': 'had not have','hadnâ€™t': 'had not','hadnâ€™tâ€™ve': 'had not have',\"hasn't\": 'has not','hasn,t': 'has not','hasn;t': 'has not','hasnÂ´t': 'has not','hasnâ€™t': 'has not',\n",
    "    \"haven't\": 'have not','haven,t': 'have not','haven;t': 'have not','havenÂ´t': 'have not','havenâ€™t': 'have not',\"he'd\": 'he would',\n",
    "    \"he'd've\": 'he would have',\"he'll\": 'he will',\n",
    "    \"he's\": 'he is','he,d': 'he would','he,d,ve': 'he would have','he,ll': 'he will','he,s': 'he is','he;d': 'he would',\n",
    "    'he;d;ve': 'he would have','he;ll': 'he will','he;s': 'he is','heÂ´d': 'he would','heÂ´dÂ´ve': 'he would have','heÂ´ll': 'he will',\n",
    "    'heÂ´s': 'he is','heâ€™d': 'he would','heâ€™dâ€™ve': 'he would have','heâ€™ll': 'he will','heâ€™s': 'he is',\"how'd\": 'how did',\"how'll\": 'how will',\n",
    "    \"how's\": 'how is','how,d': 'how did','how,ll': 'how will','how,s': 'how is','how;d': 'how did','how;ll': 'how will',\n",
    "    'how;s': 'how is','howÂ´d': 'how did','howÂ´ll': 'how will','howÂ´s': 'how is','howâ€™d': 'how did','howâ€™ll': 'how will',\n",
    "    'howâ€™s': 'how is',\"i'd\": 'i would',\"i'll\": 'i will',\"i'm\": 'i am',\"i've\": 'i have','i,d': 'i would','i,ll': 'i will',\n",
    "    'i,m': 'i am','i,ve': 'i have','i;d': 'i would','i;ll': 'i will','i;m': 'i am','i;ve': 'i have',\"isn't\": 'is not',\n",
    "    'isn,t': 'is not','isn;t': 'is not','isnÂ´t': 'is not','isnâ€™t': 'is not',\"it'd\": 'it would',\"it'll\": 'it will',\"It's\":'it is',\n",
    "    \"it's\": 'it is','it,d': 'it would','it,ll': 'it will','it,s': 'it is','it;d': 'it would','it;ll': 'it will','it;s': 'it is','itÂ´d': 'it would','itÂ´ll': 'it will','itÂ´s': 'it is',\n",
    "    'itâ€™d': 'it would','itâ€™ll': 'it will','itâ€™s': 'it is',\n",
    "    'iÂ´d': 'i would','iÂ´ll': 'i will','iÂ´m': 'i am','iÂ´ve': 'i have','iâ€™d': 'i would','iâ€™ll': 'i will','iâ€™m': 'i am',\n",
    "    'iâ€™ve': 'i have',\"let's\": 'let us','let,s': 'let us','let;s': 'let us','letÂ´s': 'let us',\n",
    "    'letâ€™s': 'let us',\"ma'am\": 'madam','ma,am': 'madam','ma;am': 'madam',\"mayn't\": 'may not','mayn,t': 'may not','mayn;t': 'may not',\n",
    "    'maynÂ´t': 'may not','maynâ€™t': 'may not','maÂ´am': 'madam','maâ€™am': 'madam',\"might've\": 'might have','might,ve': 'might have','might;ve': 'might have',\"mightn't\": 'might not','mightn,t': 'might not','mightn;t': 'might not','mightnÂ´t': 'might not',\n",
    "    'mightnâ€™t': 'might not','mightÂ´ve': 'might have','mightâ€™ve': 'might have',\"must've\": 'must have','must,ve': 'must have','must;ve': 'must have',\n",
    "    \"mustn't\": 'must not','mustn,t': 'must not','mustn;t': 'must not','mustnÂ´t': 'must not','mustnâ€™t': 'must not','mustÂ´ve': 'must have',\n",
    "    'mustâ€™ve': 'must have',\"needn't\": 'need not','needn,t': 'need not','needn;t': 'need not','neednÂ´t': 'need not','neednâ€™t': 'need not',\"oughtn't\": 'ought not','oughtn,t': 'ought not','oughtn;t': 'ought not',\n",
    "    'oughtnÂ´t': 'ought not','oughtnâ€™t': 'ought not',\"sha'n't\": 'shall not','sha,n,t': 'shall not','sha;n;t': 'shall not',\"shan't\": 'shall not',\n",
    "    'shan,t': 'shall not','shan;t': 'shall not','shanÂ´t': 'shall not','shanâ€™t': 'shall not','shaÂ´nÂ´t': 'shall not','shaâ€™nâ€™t': 'shall not',\n",
    "    \"she'd\": 'she would',\"she'll\": 'she will',\"she's\": 'she is','she,d': 'she would','she,ll': 'she will',\n",
    "    'she,s': 'she is','she;d': 'she would','she;ll': 'she will','she;s': 'she is','sheÂ´d': 'she would','sheÂ´ll': 'she will',\n",
    "    'sheÂ´s': 'she is','sheâ€™d': 'she would','sheâ€™ll': 'she will','sheâ€™s': 'she is',\"should've\": 'should have','should,ve': 'should have','should;ve': 'should have',\n",
    "    \"shouldn't\": 'should not','shouldn,t': 'should not','shouldn;t': 'should not','shouldnÂ´t': 'should not','shouldnâ€™t': 'should not','shouldÂ´ve': 'should have',\n",
    "    'shouldâ€™ve': 'should have',\"that'd\": 'that would',\"that's\": 'that is','that,d': 'that would','that,s': 'that is','that;d': 'that would',\n",
    "    'that;s': 'that is','thatÂ´d': 'that would','thatÂ´s': 'that is','thatâ€™d': 'that would','thatâ€™s': 'that is',\"there'd\": 'there had',\n",
    "    \"there's\": 'there is','there,d': 'there had','there,s': 'there is','there;d': 'there had','there;s': 'there is',\n",
    "    'thereÂ´d': 'there had','thereÂ´s': 'there is','thereâ€™d': 'there had','thereâ€™s': 'there is',\n",
    "    \"they'd\": 'they would',\"they'll\": 'they will',\"they're\": 'they are',\"they've\": 'they have',\n",
    "    'they,d': 'they would','they,ll': 'they will','they,re': 'they are','they,ve': 'they have','they;d': 'they would','they;ll': 'they will','they;re': 'they are',\n",
    "    'they;ve': 'they have','theyÂ´d': 'they would','theyÂ´ll': 'they will','theyÂ´re': 'they are','theyÂ´ve': 'they have','theyâ€™d': 'they would','theyâ€™ll': 'they will',\n",
    "    'theyâ€™re': 'they are','theyâ€™ve': 'they have',\"wasn't\": 'was not','wasn,t': 'was not','wasn;t': 'was not','wasnÂ´t': 'was not',\n",
    "    'wasnâ€™t': 'was not',\"we'd\": 'we would',\"we'll\": 'we will',\"we're\": 'we are',\"we've\": 'we have','we,d': 'we would','we,ll': 'we will',\n",
    "    'we,re': 'we are','we,ve': 'we have','we;d': 'we would','we;ll': 'we will','we;re': 'we are','we;ve': 'we have',\n",
    "    \"weren't\": 'were not','weren,t': 'were not','weren;t': 'were not','werenÂ´t': 'were not','werenâ€™t': 'were not','weÂ´d': 'we would','weÂ´ll': 'we will',\n",
    "    'weÂ´re': 'we are','weÂ´ve': 'we have','weâ€™d': 'we would','weâ€™ll': 'we will','weâ€™re': 'we are','weâ€™ve': 'we have',\"what'll\": 'what will',\"what're\": 'what are',\"what's\": 'what is',\n",
    "    \"what've\": 'what have','what,ll': 'what will','what,re': 'what are','what,s': 'what is','what,ve': 'what have','what;ll': 'what will','what;re': 'what are',\n",
    "    'what;s': 'what is','what;ve': 'what have','whatÂ´ll': 'what will',\n",
    "    'whatÂ´re': 'what are','whatÂ´s': 'what is','whatÂ´ve': 'what have','whatâ€™ll': 'what will','whatâ€™re': 'what are','whatâ€™s': 'what is',\n",
    "    'whatâ€™ve': 'what have',\"where'd\": 'where did',\"where's\": 'where is','where,d': 'where did','where,s': 'where is','where;d': 'where did',\n",
    "    'where;s': 'where is','whereÂ´d': 'where did','whereÂ´s': 'where is','whereâ€™d': 'where did','whereâ€™s': 'where is',\n",
    "    \"who'll\": 'who will',\"who's\": 'who is','who,ll': 'who will','who,s': 'who is','who;ll': 'who will','who;s': 'who is',\n",
    "    'whoÂ´ll': 'who will','whoÂ´s': 'who is','whoâ€™ll': 'who will','whoâ€™s': 'who is',\"won't\": 'will not','won,t': 'will not','won;t': 'will not',\n",
    "    'wonÂ´t': 'will not','wonâ€™t': 'will not',\"wouldn't\": 'would not','wouldn,t': 'would not','wouldn;t': 'would not','wouldnÂ´t': 'would not',\n",
    "    'wouldnâ€™t': 'would not',\"you'd\": 'you would',\"you'll\": 'you will',\"you're\": 'you are','you,d': 'you would','you,ll': 'you will',\n",
    "    'you,re': 'you are','you;d': 'you would','you;ll': 'you will',\n",
    "    'you;re': 'you are','youÂ´d': 'you would','youÂ´ll': 'you will','youÂ´re': 'you are','youâ€™d': 'you would','youâ€™ll': 'you will','youâ€™re': 'you are',\n",
    "    'Â´cause': 'because','â€™cause': 'because',\"you've\": \"you have\",\"could'nt\": 'could not',\n",
    "    \"havn't\": 'have not',\"hereâ€™s\": \"here is\",'i\"\"m': 'i am',\"i'am\": 'i am',\"i'l\": \"i will\",\"i'v\": 'i have',\"wan't\": 'want',\"was'nt\": \"was not\",\"who'd\": \"who would\",\n",
    "    \"who're\": \"who are\",\"who've\": \"who have\",\"why'd\": \"why would\",\"would've\": \"would have\",\"y'all\": \"you all\",\"y'know\": \"you know\",\"you.i\": \"you i\",\n",
    "    \"your'e\": \"you are\",\"arn't\": \"are not\",\"agains't\": \"against\",\"c'mon\": \"common\",\"doens't\": \"does not\",'don\"\"t': \"do not\",\"dosen't\": \"does not\",\n",
    "    \"dosn't\": \"does not\",\"shoudn't\": \"should not\",\"that'll\": \"that will\",\"there'll\": \"there will\",\"there're\": \"there are\",\n",
    "    \"this'll\": \"this all\",\"u're\": \"you are\", \"ya'll\": \"you all\",\"you'r\": \"you are\",\"youâ€™ve\": \"you have\",\"d'int\": \"did not\",\"did'nt\": \"did not\",\"din't\": \"did not\",\"dont't\": \"do not\",\"gov't\": \"government\",\n",
    "    \"i'ma\": \"i am\",\"is'nt\": \"is not\",\"â€˜I\":'I',' :( ':' sad '}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_contraction(x, dic):\n",
    "    for word in dic.keys():\n",
    "        if word in x:\n",
    "            x = x.replace(word, dic[word])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review'] = train['review'].apply(lambda x: correct_contraction(x, contraction_mapping))\n",
    "test['review']  = test['review'].apply(lambda x: correct_contraction(x, contraction_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_case_words = {' solimo ':' brand ',' naturewise ':' nature wise ','natrue':'nature',' sleep3 ':' sleep ',' grosssssss ': ' gross ',\n",
    "                  ' revly ': ' brand ',' asorbic ': ' ascorbic ','xssential':'brand','xssentail':'brand','ðŸ¤¢':' nauseated ','ðŸ˜”':'pensive',\n",
    "                  'ðŸ™':'frowning','ðŸ˜‰':'winkling','ðŸ˜ž':'disappointed',' mykind ':' brand ',' lasership ': ' company ','ðŸ˜¡':'angry',\n",
    "                  '\\U0001f92e':'vomiting','âš ':'danger'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_punct = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_punc_mappings = {\"â€”\": \"-\", \"â€“\": \"-\", \"_\": \"-\", 'â€': '\"', \"â€³\": '\"', 'â€œ': '\"', 'â€¢': '.', 'âˆ’': '-',\n",
    "                         \"â€™\": \"'\", \"â€˜\": \"'\", \"Â´\": \"'\", \"`\": \"'\", '\\u200b': ' ', '\\xa0': ' ','ØŒ':'','â€ž':'',\n",
    "                         'â€¦': ' ... ', '\\ufeff': ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bad_case_words(text):\n",
    "    for bad_word in bad_case_words:\n",
    "        if bad_word in text:\n",
    "            text = text.replace(bad_word, bad_case_words[bad_word])\n",
    "    return text\n",
    "\n",
    "def clean_special_punctuations(text):\n",
    "    for punc in special_punc_mappings:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, special_punc_mappings[punc])\n",
    "    # remove_diacritics donÂ´t' ->  'don t'\n",
    "    #text = remove_diacritics(text)\n",
    "    return text\n",
    "\n",
    "def spacing_punctuation(text):\n",
    "    \"\"\"\n",
    "    add space before and after punctuation and symbols\n",
    "    \"\"\"\n",
    "    for punc in all_punct:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, f' {punc} ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = clean_special_punctuations(text)\n",
    "    text = spacing_punctuation(text)\n",
    "    text = clean_bad_case_words(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"review\"] = train[\"review\"].apply(preprocess)\n",
    "test[\"review\"] = test[\"review\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review'].replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "test['review'].replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review'] = train['review'].str.replace(\" '\",' ').str.replace(' s ','')\n",
    "test['review'] = test['review'].str.replace(\" '\",'').str.replace(' s ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train1.csv',index=False)\n",
    "test.to_csv('test1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['0', '1', '10', '11', '12', '13', '14', '15', '16', '17','18', '19', '2', '20', '3', '4', '5', '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = ''\n",
    "TEXT_COL = 'review'\n",
    "\n",
    "data_lm = TextClasDataBunch.from_df(MODEL_PATH,train_df,valid_df=val_df, test_df=test, text_cols=[TEXT_COL], label_cols=label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "awd_lstm_clas_config = dict(emb_sz=400, n_hid=1150, n_layers=3, pad_token=1, qrnn=False, bidir=False, output_p=0.4,\n",
    "                       hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = text_classifier_learner(data_lm, AWD_LSTM, max_len=100,config=awd_lstm_clas_config, pretrained = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['../input/awd-lstm/lstm_wt103.pth','../input/awd-lstm/itos_wt103.pkl']\n",
    "learner.load_pretrained(*fnames, strict=False)\n",
    "learner.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.641571</td>\n",
       "      <td>0.558149</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.457231</td>\n",
       "      <td>0.369388</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.unfreeze()\n",
    "learner.fit_one_cycle(2, 2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    the get_preds method does not yield the elements in order by default\n",
    "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
    "    \"\"\"\n",
    "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "    #y = learner.get_preds(ds_type)[1].detach().cpu().numpy()\n",
    "    \n",
    "    sampler = [i for i in data_lm.dl(ds_type).sampler]\n",
    "    reverse_sampler = np.argsort(sampler)\n",
    "    \n",
    "    return preds[reverse_sampler, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1776"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = get_preds_as_nparray(DatasetType.Test)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({0:preds[:,0], 1:preds[:,1], 10:preds[:,2], 11:preds[:,3], 12:preds[:,4], 13:preds[:,5], 14:preds[:,6], \n",
    "                        15:preds[:,7], 16:preds[:,8], 17:preds[:,9],18:preds[:,10], 19:preds[:,11], 2:preds[:,12], 20:preds[:,12],\n",
    "                        3:preds[:,14], 4:preds[:,15], 5:preds[:,16], 6:preds[:,17], 7:preds[:,18] ,8:preds[:,19] , 9:preds[:,20]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>2</th>\n",
       "      <th>20</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.256656</td>\n",
       "      <td>0.351148</td>\n",
       "      <td>0.237631</td>\n",
       "      <td>0.351388</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.291281</td>\n",
       "      <td>0.510873</td>\n",
       "      <td>0.199369</td>\n",
       "      <td>0.305037</td>\n",
       "      <td>0.369061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288414</td>\n",
       "      <td>0.322546</td>\n",
       "      <td>0.322546</td>\n",
       "      <td>0.275172</td>\n",
       "      <td>0.274005</td>\n",
       "      <td>0.250349</td>\n",
       "      <td>0.304663</td>\n",
       "      <td>0.252855</td>\n",
       "      <td>0.237475</td>\n",
       "      <td>0.215506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266111</td>\n",
       "      <td>0.176097</td>\n",
       "      <td>0.264294</td>\n",
       "      <td>0.657040</td>\n",
       "      <td>0.261072</td>\n",
       "      <td>0.307886</td>\n",
       "      <td>0.405986</td>\n",
       "      <td>0.236624</td>\n",
       "      <td>0.253040</td>\n",
       "      <td>0.230334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223259</td>\n",
       "      <td>0.222224</td>\n",
       "      <td>0.222224</td>\n",
       "      <td>0.237521</td>\n",
       "      <td>0.235706</td>\n",
       "      <td>0.237652</td>\n",
       "      <td>0.233382</td>\n",
       "      <td>0.232298</td>\n",
       "      <td>0.199434</td>\n",
       "      <td>0.244199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         10        11        12        13        14  \\\n",
       "0  0.256656  0.351148  0.237631  0.351388  0.278126  0.291281  0.510873   \n",
       "1  0.266111  0.176097  0.264294  0.657040  0.261072  0.307886  0.405986   \n",
       "\n",
       "         15        16        17    ...           19        2         20  \\\n",
       "0  0.199369  0.305037  0.369061    ...     0.288414  0.322546  0.322546   \n",
       "1  0.236624  0.253040  0.230334    ...     0.223259  0.222224  0.222224   \n",
       "\n",
       "         3         4         5         6         7         8         9   \n",
       "0  0.275172  0.274005  0.250349  0.304663  0.252855  0.237475  0.215506  \n",
       "1  0.237521  0.235706  0.237652  0.233382  0.232298  0.199434  0.244199  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame(dataset).T\n",
    "rslt = pd.DataFrame(np.zeros((0,6)), columns=['top1','top2','top3','top4','top5','top6'])\n",
    "for i in x.columns:\n",
    "    df1row = pd.DataFrame(x.nlargest(6, i).index.tolist(), index=['top1','top2','top3','top4','top5','top6']).T\n",
    "    rslt = pd.concat([rslt, df1row], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = rslt.reset_index()\n",
    "rslt.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(test,rslt,left_index=True,right_index=True,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traildecis(df):\n",
    "    df = df.astype(str)\n",
    "    df = df.astype(str).replace('\\.0', '', regex=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['top1'] = traildecis(final['top1'])\n",
    "final['top2'] = traildecis(final['top2'])\n",
    "final['top3'] = traildecis(final['top3'])\n",
    "final['top4'] = traildecis(final['top4'])\n",
    "final['top5'] = traildecis(final['top5'])\n",
    "final['top6'] = traildecis(final['top6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>count</th>\n",
       "      <th>top1</th>\n",
       "      <th>top2</th>\n",
       "      <th>top3</th>\n",
       "      <th>top4</th>\n",
       "      <th>top5</th>\n",
       "      <th>top6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i use chia seed in my protein shakes .  these ...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do not waste your money .  no change .  no res...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i use the book  fortify your life  by tieraona...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i used to be loyal customer to this brand .  i...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have not received it yet .  shipping</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  count top1 top2 top3  \\\n",
       "0  i use chia seed in my protein shakes .  these ...      2   14   17   11   \n",
       "1  do not waste your money .  no change .  no res...      1   11   14   13   \n",
       "2  i use the book  fortify your life  by tieraona...      2   11   14   17   \n",
       "3  i used to be loyal customer to this brand .  i...      4    0   17   12   \n",
       "4             i have not received it yet .  shipping      1   15   12    0   \n",
       "\n",
       "  top4 top5 top6  \n",
       "0    1    2   20  \n",
       "1    0   10   12  \n",
       "2    2   20   19  \n",
       "3   19    2   20  \n",
       "4   11   17    6  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging(data):\n",
    "    beep =[]\n",
    "    for index, row in data.iterrows():\n",
    "        l = row[\"count\"]\n",
    "    \n",
    "        if(l==1):\n",
    "            row['top1'] = row['top1']\n",
    "    \n",
    "        elif(l==2):\n",
    "            row['top1'] = row['top1']+','+row['top2']\n",
    "        \n",
    "        elif(l==3):\n",
    "            row['top1'] = row['top1']+','+row['top2']+','+row['top3']\n",
    "    \n",
    "        elif(l==4):\n",
    "            row['top1'] = row['top1']+','+row['top2']+','+row['top3']+','+row['top4']\n",
    "        \n",
    "        elif(l==5):\n",
    "            row['top1'] = row['top1']+','+row['top2']+','+row['top3']+','+row['top4']+','+row['top5']\n",
    "        \n",
    "        elif(l==6):\n",
    "            row['top1'] = row['top1']+','+row['top2']+','+row['top3']+','+row['top4']+','+row['top5']+','+row['top6']\n",
    "            \n",
    "        beep.append(row['top1'])\n",
    "    \n",
    "    data['new'] = beep\n",
    "    \n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = merging(final)\n",
    "final.drop(['top1','top2','top3','top4','top5','top6'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_final = pd.DataFrame(final.new.str.split(',').tolist(), index=final.review).stack()\n",
    "new_final = new_final.reset_index([0, 'review'])\n",
    "new_final.columns = ['review', 'topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test = pd.merge(tests,new_final,left_index=True,right_index=True,how='inner')\n",
    "sub_test.drop(['review'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2553"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test['topic'] = sub_test['topic'].astype(int)\n",
    "sub_test['topic'] = le_review.inverse_transform(sub_test['topic'])\n",
    "sub_test.to_csv('submission_amazon.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bad Taste/Flavor          543\n",
       "Packaging                 491\n",
       "Not Effective             435\n",
       "Quality/Contaminated      349\n",
       "Texture                   338\n",
       "Shipment and delivery     196\n",
       "Allergic                  111\n",
       "Color and texture          59\n",
       "Wrong Product received     13\n",
       "Too big to swallow          9\n",
       "Pricing                     3\n",
       "Too Sweet                   3\n",
       "Ingredients                 2\n",
       "Smells Bad                  1\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_test['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
